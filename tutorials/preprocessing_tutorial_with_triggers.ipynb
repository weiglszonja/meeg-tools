{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing pipeline\n",
    "\n",
    "\n",
    "This pipeline aims to serve as a semiautomatic and reproducible framework for preprocessing EEG signals before performing time-frequency-based analysis. It minimizes the manual steps required to clean the data based on visual inspection. It is advised to revisit the cleaned epochs before writing the final preprocessed file. \n",
    "\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. __Temporal filtering__\n",
    "\n",
    "High-frequency artefacts and slow drifts are removed with a zero-phase bandpass filter using mne-Python [1]. The cutoff frequencies (0.5 - 45 Hz) can be modified in the utils folder in the configuration file (config.py). \n",
    "\n",
    "\n",
    "2. __Create epochs__ \n",
    "\n",
    "Epochs are nonoverlapping data segments created from the continuous data with a duration of 1 seconds. The length of epochs can be changed in the configuration file.\n",
    "Epochs can be created from (1) events; there is a custom method that created epochs based on annotations in the raw data, (2) without events, data segments are created from the beginning of the raw data. \n",
    "\n",
    "\n",
    "3. __Outlier data rejection__  \n",
    "\n",
    "    3.1. _Preliminar rejection_  \n",
    "Epochs are rejected based on a global threshold on the z-score (> 3) of the epoch variance and amplitude range.\n",
    "\n",
    "    3.2. _ICA decomposition_  \n",
    "The default method is the infomax algorithm, however it can be changed in the configuration file along with the number of components and the decimation parameter. Components containing blink artefacts are automatically marked with mne-Python.\n",
    "The ICA sourced can be visualized and interactively selected and rejected based on their topographies, time-courses or frequency spectra. The number of components that were removed from the data are documented in the “description” field of the epochs instance “info” structure.\n",
    "\n",
    "    3.3. _Autoreject_  \n",
    "Autoreject [2, 3] uses unsupervised learning to estimate the rejection threshold for the epochs. In order to reduce computation time that increases with the number of segments and channels, autoreject can be fitted on a representative subset of epochs (25% of total epochs). Once the parameters are learned, the solution can be applied to any data that contains channels that were used during fit.\n",
    "\n",
    "\n",
    "4. __Outlier channel interpolation__\n",
    "\n",
    "The Random Sample Consensus (RANSAC) algorithm [4] selects a random subsample of good channels to make predictions of each channel in small non-overlapping 4 seconds long time windows. It uses a method of spherical splines (Perrin et al., 1989) to interpolate the bad sensors. The sensors that were interpolated are added to the \"description\" field of the epochs \"info\" structure. \n",
    "\n",
    "\n",
    "<img src=\"static/preprocessing_pipeline_diagram.svg\">\n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "[1] A. Gramfort, M. Luessi, E. Larson, D. Engemann, D. Strohmeier, C. Brodbeck, R. Goj, M. Jas, T. Brooks, L. Parkkonen, M. Hämäläinen, MEG and EEG data analysis with MNE-Python, Frontiers in Neuroscience, Volume 7, 2013, ISSN 1662-453X\n",
    "\n",
    "[2] Mainak Jas, Denis Engemann, Federico Raimondo, Yousra Bekhti, and Alexandre Gramfort, “Automated rejection and repair of bad trials in MEG/EEG.” In 6th International Workshop on Pattern Recognition in Neuroimaging (PRNI), 2016.\n",
    "\n",
    "[3] Mainak Jas, Denis Engemann, Yousra Bekhti, Federico Raimondo, and Alexandre Gramfort. 2017. “Autoreject: Automated artifact rejection for MEG and EEG data”. NeuroImage, 159, 417-429.\n",
    "\n",
    "[4] Bigdely-Shamlo, N., Mullen, T., Kothe, C., Su, K. M., & Robbins, K. A. (2015). The PREP pipeline: standardized preprocessing for large-scale EEG analysis. Frontiers in neuroinformatics, 9, 16.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "\n",
    "```%matplotlib qt``` is the recommended backend for interactive visualization (can be slower);    \n",
    "\n",
    "switch to ```%matplotlib inline``` for (faster) static plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "from meeg_tools.preprocessing import *\n",
    "from meeg_tools.utils.epochs import create_epochs_from_events, create_metadata\n",
    "from meeg_tools.utils.raw import read_raw_measurement, filter_raw\n",
    "from meeg_tools.utils.log import update_log\n",
    "\n",
    "from meeg_tools.utils.config import settings\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data\n",
    "\n",
    "\n",
    "See [this](https://mne.tools/stable/auto_tutorials/io/20_reading_eeg_data.html) documentation for help with supported file formats.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Use the widget to navigate to the experiment folder path and select an EEG file \n",
    "base_path = '/Volumes/crnl-memo-hd/TMS_rewiring/'\n",
    "fc = FileChooser(base_path)\n",
    "fc.filter_pattern = ['*.vhdr', '*.edf']\n",
    "\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Load selected file\n",
    "raw = read_raw_measurement(raw_file_path=fc.selected)\n",
    "raw.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal filtering\n",
    "\n",
    "- bandpass filter (0.5 - 45 Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings['bandpass_filter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_bandpass = filter_raw(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create epochs\n",
    "\n",
    "- select the events for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings['epochs']['start_time'] = -0.25\n",
    "settings['epochs']['end_time'] = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_ids = np.concatenate([np.arange(10, 53, 1), \n",
    "                             np.arange(10, 53, 1) + 100,\n",
    "                            [211, 212, 213, 214, 215, 216]])\n",
    "\n",
    "epochs = create_epochs_from_events(raw=raw_bandpass, event_ids=[events_ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create metadata for epochs (optional)\n",
    "\n",
    "- adding metadata makes it easier to select epochs of different types\n",
    "- custom triggers are selected from the raw instance\n",
    "\n",
    "- metadata can be added or replaced later (e.g. after preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = create_metadata(epochs)\n",
    "metadata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.metadata = metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can filter epochs as a query\n",
    "epochs[\"triplet == 'H' & answer == 'incorrect'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs[\"epoch == 5 & triplet == 'L'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subselecting epochs \n",
    "# Here we could also include thrills, repetitions, or practice stimuli.\n",
    "# ICA should not run on duplicate data (epochs should not be overlapping!)\n",
    "\n",
    "epochs = epochs[\"triplet == 'L' | triplet == 'H'\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run preprocessing\n",
    "\n",
    "\n",
    "### 1.1. Preliminary epoch rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "epochs_faster = prepare_epochs_for_ica(epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Run ICA\n",
    "\n",
    "\n",
    "The parameters are: 32 ICA components using [\"infomax\"](https://mne.tools/stable/generated/mne.preprocessing.infomax.html) algorithm. \n",
    "\n",
    "When visualizing the components, it is recommended to subset the data (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ica = run_ica(epochs=epochs_faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot component topographies\n",
    "ica.plot_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualize components on epochs\n",
    "# Subset epochs to reduce execution time (e.g. take epochs from every 5th event)\n",
    "subset = list(epochs.event_id.keys())[::5]\n",
    "# Exclude components by selecting them, right click on component name to visulize source:\n",
    "ica.plot_sources(epochs_faster[subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# After selecting the components to exclude, apply ICA to epochs\n",
    "# Document the number of excluded components\n",
    "ica.apply(epochs_faster.load_data())\n",
    "epochs_faster.info['description'] = f'n_components: {len(ica.exclude)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Visualize ICA cleaned epochs (optional)\n",
    "\n",
    "This step can be repeated after each preprocessing step, or you can also do a final inspection at the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Optional\n",
    "epochs_faster[subset].plot(n_epochs=10, n_channels=32, scalings={'eeg': 20e-6},)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Optional\n",
    "# If you found a component that should have been excluded but it wasn't you can exclude it here:\n",
    "ica.plot_sources(epochs_faster)\n",
    "\n",
    "# After selecting the components to exclude, apply ICA to epochs\n",
    "# Document the number of excluded components\n",
    "ica.apply(epochs_faster)\n",
    "epochs_faster.info['description'] = f'n_components: {len(ica.exclude)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Save cleaned epochs (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Create folder for preprocessed and interim files\n",
    "folder_name = 'preprocessed'\n",
    "epochs_path = os.path.join(base_path, folder_name, 'epochs_asrt')\n",
    "\n",
    "\n",
    "# Create path to epoch files\n",
    "if not os.path.exists(epochs_path):\n",
    "    os.makedirs(epochs_path)\n",
    "\n",
    "# Save ICA cleaned epochs \n",
    "fid = epochs.info['fid']\n",
    "epochs_faster.info['fid'].update(f'{fid}_ICA')\n",
    "postfix = '-epo.fif.gz'\n",
    "epochs_faster.save(os.path.join(epochs_path, f'{epochs_faster.info['fid']}{postfix}'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_faster.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Create a log file \n",
    "\n",
    "We can create a log file for the preprocessed data and store metadata\n",
    "that could be useful to remember. You can add more columns to this, or \n",
    "remove the ones that are not needed. For documentation purporses, it is \n",
    "recommended to store the number of rejected and total epochs, the number of\n",
    "ICA components that were rejected, the number of interpolated electrodes etc.\n",
    "You can also add a column with \"notes\" to add custom descriptions about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path = os.path.join(os.path.join(base_path, 'preprocessed', 'epochs_asrt'), 'log.csv')\n",
    "update_log(log_file_path, epochs_faster, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Run autoreject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "reject_log = run_autoreject(epochs_faster.load_data(), n_jobs=11, subset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you can decide how strict should be the epoch rejection.\n",
    "# You can drop only those that were marked as bad epochs, or a more \n",
    "# strict rejection threshold can be if you drop epochs where more than\n",
    "# 15% of the channels were marked as noisy.\n",
    "\n",
    "# You can plot the epochs with Autoreject, where bad epochs are marked with\n",
    "# red colors. \n",
    "\n",
    "# reject_log.plot_epochs(epochs_faster)\n",
    "\n",
    "\n",
    "# rejecting only bad epochs\n",
    "# epochs_autoreject = epochs_faster.copy().drop(reject_log.bad_epochs, reason='AUTOREJECT')\n",
    "\n",
    "# rejecting those epochs too where more than 15% of the channels are marked as noisy\n",
    "bads = np.where(np.count_nonzero(reject_log.labels, axis=1) > 0.15 * epochs_faster.info['nchan'])[0].tolist()\n",
    "\n",
    "# you can plot just the bad epochs to double check how strict this rejection is\n",
    "# if bads: \n",
    "#     epochs_faster[bads].plot(n_epochs=10,\n",
    "#                                 scalings={'eeg': 20e-6},\n",
    "#                                 n_channels=32)\n",
    "\n",
    "\n",
    "epochs_autoreject = epochs_faster.copy().drop(bads, reason='AUTOREJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "epochs_autoreject.plot(n_epochs=10, n_channels=32, scalings={'eeg': 20e-6},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# save clean epochs\n",
    "fid = epochs.info['fid']\n",
    "epochs_autoreject.info['fid'].update(f'{fid}_ICA_autoreject')\n",
    "postfix = '-epo.fif.gz'\n",
    "epochs_autoreject.save(os.path.join(epochs_path, f'{epochs_autoreject.info['fid']}{postfix}'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_log(log_file_path, epochs_autoreject, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run ransac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ransac = run_ransac(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ransac = epochs_autoreject.copy()\n",
    "epochs_ransac.info['bads'] = ransac.bad_chs_\n",
    "# Alternatively, you can interpolate the channels that were reported before \n",
    "# epochs_ransac.info['bads'] = ransac.report\n",
    "\n",
    "epochs_ransac.interpolate_bads(reset_bads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# inspect which sensors were interpolated (if any)\n",
    "epochs_ransac.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final visual inspection\n",
    "\n",
    "Mark epochs that should be dropped,  etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "epochs_ransac.plot(n_epochs=10,\n",
    "                       n_channels=32,\n",
    "                       # group_by='position',\n",
    "                       scalings={'eeg': 20e-6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there were no bad channels found, however there are clearly some bad ones\n",
    "# you can you the epochs_ransac object to mark bad channels\n",
    "\n",
    "# example\n",
    "# epochs_ransac.info['bads'] = ['Fp1', 'F7']\n",
    "# epochs_ransac.interpolate_bads()\n",
    "# bads_str = ', '.join(['Fp1', 'F7'])\n",
    "# epochs_ransac.info.update(description=epochs_ransac.info['description'] + ', interpolated: ' + bads_str)\n",
    "# log['n_interpolated'].update(len(['Fp1', 'F7']))\n",
    "\n",
    "\n",
    "# However, if you found additional channels (addition to those that were found with RANSAC)\n",
    "# then you should use the epochs_autoreject object (don't interpolate the same object twice)\n",
    "\n",
    "# example\n",
    "# epochs_ransac = epochs_autoreject.copy()\n",
    "# epochs_ransac.info['bads'] = ['Fp1', 'F7']\n",
    "# bads_str = ', '.join(['Fp1', 'F7'])\n",
    "# epochs_ransac.info.update(description=epochs_ransac.info['description'] + ', interpolated: ' + bads_str)\n",
    "# log['n_interpolated'].update(len(['Fp1', 'F7']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Apply baseline and set average reference\n",
    "\n",
    "### 5.1. Apply baseline (optional)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ransac.apply_baseline(baseline=(-0.25, 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Set average reference\n",
    "\n",
    "To set a “virtual reference” that is the average of all channels, you can use set_eeg_reference() with ref_channels='average'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "epochs_ransac.set_eeg_reference('average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save cleaned epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save clean epochs\n",
    "fid = epochs.info['fid']\n",
    "epochs_ransac.info['fid'].update(f'{fid}_ICA_autoreject_ransac')\n",
    "postfix = '-epo.fif.gz'\n",
    "epochs_ransac.save(os.path.join(epochs_path, f'{epochs_ransac.info['fid']}{postfix}'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_log(log_file_path, epochs_ransac, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-frequency analysis\n",
    "### Evoked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset channels\n",
    "\n",
    "ch_names = ['F7', 'F5', 'F3', 'FC5', 'FC3',\n",
    "           'F1', 'Fz', 'F2', 'FC1', 'FCz', 'FC2',\n",
    "           'F4', 'F6', 'F8', 'FC4', 'FC6',\n",
    "           'FT7', 'T7', 'TP7', \n",
    "           'C3', 'Cz', 'C4',\n",
    "           'FT8', 'T8', 'TP8',\n",
    "           'CP5', 'CP3', 'P7', 'P5', 'P3',\n",
    "           'CP1', 'CPz', 'CP2', 'P1', 'Pz', 'P2',\n",
    "           'CP4', 'CP6', 'P4', 'P6', 'P8',\n",
    "           'PO3', 'PO7', 'O1',\n",
    "           'PO4', 'PO8', 'O2',]\n",
    "\n",
    "epochs_evoked = epochs_ransac.copy().pick_channels(ch_names, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = epochs_evoked.plot_sensors(show_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_evoked.plot(n_epochs=10,\n",
    "                       n_channels=32,\n",
    "                       # group_by='position',\n",
    "                       scalings={'eeg': 20e-6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bands = [(4, 8, 'Theta (4 - 8 Hz)'), (8, 13, 'Alpha (8 - 13 Hz)'), (13, 30, 'Beta (13 - 30 Hz)'), (30, 45, 'Gamma (30 - 45 Hz)')]\n",
    "#epochs_ransac_ordered.plot_psd_topomap(bands=bands, vlim='joint', ch_type='eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked_epoch_1_H = epochs_evoked[\"epoch == 1 & triplet == 'H'\"].average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked_epoch_1_H.detrend().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_evoked.detrend().plot_joint(times=[0.0, 0.11, 0.15, 0.3, 0.6, 0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_evoked[\"epoch == 1 & triplet == 'H'\"].plot_psd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}